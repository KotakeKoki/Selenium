{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e4826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b77461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# +\n",
    "#https://www.ncbi.nlm.nih.gov/home/about/policies/\n",
    "#上記ページの\"Guidelines for Scripting Calls to NCBI Servers\"には\"Do not overload NCBI's systems. \"Make no more than 3 requests every 1 second.\"\n",
    "#一つずつクエリを送り、クリックのたびに数秒待つ分には問題ないと解釈し、以下のコードを記す。\n",
    "options = Options()\n",
    "options.headless = True\n",
    "\n",
    "browser= webdriver.Chrome(options=options)\n",
    "df = pd.DataFrame()\n",
    "doc_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "#keywords.txtファイルに改行区切りでkeywordを入れておく。\n",
    "with open('keywords.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        df = pd.DataFrame()\n",
    "        doc_df = pd.DataFrame()\n",
    "        doc_count = 0\n",
    "        try:\n",
    "            url= \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "            browser.get(url)\n",
    "            sleep(1)\n",
    "            search_win = browser.find_element(By.CLASS_NAME,\"term-input.tt-input\")\n",
    "            search_win.send_keys(line)\n",
    "            \n",
    "            try: \n",
    "                search_button = browser.find_element(By.CLASS_NAME,\"search-btn\")\n",
    "                search_button.click()\n",
    "                sleep(3)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            hit = browser.find_element(By.CLASS_NAME,\"results-amount\").text\n",
    "            hit_num = re.sub(r\"\\D\", \"\", hit)\n",
    "            print(line+\":hit\"+hit_num+\"papers\")\n",
    "            \n",
    "            num = int(int(hit_num)/10)\n",
    "            \n",
    "            if num >200:\n",
    "                print(\"too many articles to read.I'll get only first 200.\")\n",
    "                num = 200\n",
    "                \n",
    "            for i in range(num + 1):\n",
    "                try: \n",
    "                    #for i in range(len(docs)):\n",
    "                    for i in range(10):\n",
    "                        docs = browser.find_elements(By.CSS_SELECTOR,'a[data-ga-category=\"result_click\"]')\n",
    "\n",
    "                        doc = {}\n",
    "                        doc_button = docs[i]\n",
    "                        doc_button.click()\n",
    "                        doc_count += 1\n",
    "                        \n",
    "                        name= browser.find_element(By.CLASS_NAME,\"heading-title\")\n",
    "                        year = browser.find_element(By.CLASS_NAME,\"cit\")\n",
    "                        first = browser.find_element(By.CLASS_NAME,\"full-name\")\n",
    "                        journal = browser.find_element(By.ID,\"full-view-journal-trigger\")\n",
    "                        doc_url = browser.current_url\n",
    "                        #print(\"OK1\")\n",
    "\n",
    "                        try:\n",
    "                            abstract = browser.find_element(By.CLASS_NAME,\"abstract-content.selected\")\n",
    "                        except:\n",
    "                            abstract = browser.find_element(By.CLASS_NAME,\"empty-abstract\")\n",
    "\n",
    "                        #print(\"OK2\")\n",
    "                        #print(abstract.text)\n",
    "\n",
    "\n",
    "                        doc[\"name\"] = name.text\n",
    "                        doc[\"year\"] = re.split('[;: ]', year.text)[0]\n",
    "                        doc[\"first\"] = first.text\n",
    "                        doc[\"url\"] = doc_url\n",
    "                        doc[\"journal\"] = journal.text\n",
    "                        doc[\"abstract\"] = abstract.text\n",
    "\n",
    "                        if \"df\" in globals():\n",
    "                            doc_df = pd.DataFrame(doc,index = [0])\n",
    "                            df = pd.concat([doc_df,df],axis=0)\n",
    "                            #print(\"a\")\n",
    "                        else:\n",
    "                            df= pd.DataFrame(doc,index = [0])\n",
    "                        #print(\"3\")\n",
    "                        sleep(2)\n",
    "                        browser.back()\n",
    "                        sleep(3)\n",
    "                    #10記事抜き出したら次のページへ\n",
    "                    next_btn = browser.find_element(By.CLASS_NAME,\"button-wrapper.next-page-btn\")\n",
    "                    next_btn.click()\n",
    "                    sleep(5)               \n",
    "                except:\n",
    "                    if int(doc_count) == int(hit_num)  or doc_count == 200:\n",
    "                        print(\"all done.\")\n",
    "                    else:\n",
    "                        print(\"probably including an error. Please check it\")\n",
    "\n",
    "\n",
    "            dt_now = datetime.datetime.now()\n",
    "            df.to_csv(line +\"_\" + hit_num + \"hit_\" + dt_now.strftime('%Y_%m_%d_%H_%M')+\".csv\",index = False)\n",
    "        except:\n",
    "            print(\"no papers\")\n",
    "            dt_now = datetime.datetime.now()\n",
    "            df.to_csv(line + \"_nohit\" + dt_now.strftime('%Y_%m_%d_%H_%M')+\".csv\",index = False)\n",
    "            pass\n",
    "\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa12a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "print(len(author))\n",
    "print(doc_count)\n",
    "print(hit_num)\n",
    "print( int(doc_count) == int(hit_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ff540",
   "metadata": {},
   "source": [
    "<h1>Seleniumの強み</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb045a3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#url = \"https://www.ncbi.nlm.nih.gov/gene/5468/ortholog/?scope=7776\"\n",
    "\n",
    "#res = requests.get(url)\n",
    "#soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "#soup\n",
    "\n",
    "#javascriptのせいで、オルソログのページのHTMLはBeautiful　Soupでは上手く取得できない。\n",
    "#Seleniumから以下のよう(page_source)にする。すると人間が見たままのページのHTMLが出る。\n",
    "#ここにSeleniumの強みがある。\n",
    "#browser= webdriver.Chrome()\n",
    "#browser.get(url)\n",
    "#source_code = browser.page_source#これを参照しながらfind_elementをすれば良い。\n",
    "#tag = browser.find_element_by_css_selector('a[data-ga-label=\"Rattus norvegicus\"]')\n",
    "#tag.click()\n",
    "#categoryItems = soup.find(\"dl\",attrs={\"id\":\"summaryDl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00b20ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_06_01_11:39.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444bfa1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fd9a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ddcec1ebe89a027dd8387debcf83fdbf916e0c695273745849a5938d2ceab9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
